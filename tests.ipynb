{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract as tess\n",
    "tess.pytesseract.tesseract_cmd = os.path.join(r'Tesseract-OCR\\tesseract.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData:\n",
    "\n",
    "    def __init__(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        \n",
    "        self.doc_text = ''\n",
    "        self.text_struct = ''\n",
    "        self.indx_clv_elec = -1\n",
    "\n",
    "        self.indx_ready = set()\n",
    "\n",
    "        self.msgs = []\n",
    "\n",
    "        self.send_data = []\n",
    "        self.perc_found = 0\n",
    "\n",
    "        self.graph_data = {}\n",
    "\n",
    "        self.data_f = {\n",
    "                'nombre': '',\n",
    "                'domicilio': '',\n",
    "                'clave_elector': '',\n",
    "                'curp': '',\n",
    "                'registro': '',\n",
    "                'estado': '',\n",
    "                'municipio': '',\n",
    "                'seccion': '',\n",
    "                'localidad': '',\n",
    "                'emision': '',\n",
    "                'vigencia': '',\n",
    "                'nacimiento': '',\n",
    "                'sexo': ''\n",
    "            }\n",
    "    \n",
    "\n",
    "    def extract_text_from_image(self):\n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(self.img_path)\n",
    "        \n",
    "        # Resize the image for better accuracy (optional)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply a median blur to reduce noise\n",
    "        gray_image = cv2.medianBlur(gray_image, 3)\n",
    "        \n",
    "        # Apply adaptive thresholding\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(\n",
    "            gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 2)\n",
    "        \n",
    "        # Apply morphological operations to close gaps and reduce noise\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        morph_image = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Apply Canny edge detection\n",
    "        edges = cv2.Canny(morph_image, 50, 150)\n",
    "        \n",
    "        # Find contours in the edged image\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Initialize a variable to store the largest rectangle contour\n",
    "        largest_rect = None\n",
    "        largest_area = 0\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area < 1000:  # Filter out small contours by area\n",
    "                continue\n",
    "\n",
    "            # Approximate the contour to a polygon\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # Check if the approximated contour has four points (rectangle)\n",
    "            if len(approx) == 4:\n",
    "                if area > largest_area:\n",
    "                    largest_area = area\n",
    "                    largest_rect = approx\n",
    "        \n",
    "        # Draw all contours for visualization\n",
    "        contour_image = image.copy()\n",
    "        cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  # Draw all contours in green\n",
    "        \n",
    "        # Draw all rectangular contours\n",
    "        for contour in contours:\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            if len(approx) == 4:\n",
    "                cv2.drawContours(contour_image, [approx], -1, (255, 0, 0), 2)  # Draw all rectangles in blue\n",
    "        \n",
    "        # Draw the largest rectangle contour in red\n",
    "        if largest_rect is not None:\n",
    "            cv2.drawContours(contour_image, [largest_rect], -1, (0, 0, 255), 2)  # Draw the largest rectangle in red\n",
    "\n",
    "        # Display the image with contours\n",
    "\n",
    "        # If a rectangle was found, crop the image to that rectangle\n",
    "        if largest_rect is not None:\n",
    "            x, y, w, h = cv2.boundingRect(largest_rect)\n",
    "            cropped_image = image[y:y+h, x:x+w]\n",
    "        else:\n",
    "            cropped_image = image\n",
    "        \n",
    "        #cv2.imshow('cropped_image', cropped_image)\n",
    "\n",
    "\n",
    "        cropped_image_re = cv2.resize(cropped_image, (0, 0), fx=1.8, fy=1.8)\n",
    "\n",
    "        \n",
    "        # Convert the cropped image to grayscale\n",
    "        gray_cropped = cv2.cvtColor(cropped_image_re, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.imshow('gray_cropped', gray_cropped)\n",
    "\n",
    "        # Apply a median blur to reduce noise\n",
    "        gray_cropped = cv2.medianBlur(gray_cropped, 1)\n",
    "\n",
    "        # Apply binary thresholding\n",
    "        _, binary_image = cv2.threshold(gray_cropped, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        #cv2.imshow('binary_image', binary_image)\n",
    "\n",
    "        \n",
    "        # Use Tesseract to extract text\n",
    "        text = tess.image_to_string(binary_image)\n",
    "        \n",
    "\n",
    "\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        self.doc_text = text\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def structure_data(self):\n",
    "\n",
    "        lines = self.doc_text.split('\\n')\n",
    "        data = {}\n",
    "        count = 0\n",
    "        for i in range(len(lines)):\n",
    "\n",
    "            if lines[i] != '' and len(lines[i]) >= 3:\n",
    "                data[count] = lines[i]\n",
    "                count += 1\n",
    "\n",
    "        self.text_struct = data\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def extract_NOMBRE_NACIM_SEX(self):\n",
    "        pattern = re.compile(r'\\b\\w*NOMBRE\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                self.indx_ready.add(key) #Index where the word 'NAME' is.\n",
    "\n",
    "                line_data_1 = self.text_struct[key+1].split(' ')\n",
    "                self.indx_ready.add(key + 1) #Index where the word First last name is.\n",
    "                last_name_1 = line_data_1[0]\n",
    "\n",
    "                #The born date is in the same line as the first last name\n",
    "                self.data_f['nacimiento'] = line_data_1[1]\n",
    "\n",
    "                line_data_2 = self.text_struct[key + 2].split(' ')\n",
    "                self.indx_ready.add(key + 2) #Index where the word Second last name is.\n",
    "                last_name_2 = line_data_2[0]\n",
    "\n",
    "                #The sex is in the same line as the second last name\n",
    "                if len(line_data_2) >= 3:\n",
    "                    \n",
    "                    self.data_f['sexo'] = line_data_2[2]\n",
    "                \n",
    "                raw_name = self.text_struct[key + 3].split(' ')\n",
    "                self.indx_ready.add(key + 3) #Index where the word Name is.\n",
    "\n",
    "                filter_name = [part for part in raw_name if len(part) > 1]\n",
    "        \n",
    "                # Join the filtered words into a single string\n",
    "                name = ' '.join(filter_name)\n",
    "                \n",
    "                self.data_f['nombre'] = f'{name} {last_name_1} {last_name_2}'\n",
    "\n",
    "    #Find Data   \n",
    "    def extract_DOMICILIO(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bDOMIC\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, value in self.text_struct.items():\n",
    "            if pattern.search(value):\n",
    "\n",
    "                indx_domici = key\n",
    "                direc = ''\n",
    "                for key_2, value in self.text_struct.items():\n",
    "                    if indx_domici < key_2 < self.indx_clv_elec:\n",
    "                        direc += ' ' + value\n",
    "\n",
    "                self.data_f['domicilio'] = direc\n",
    "                return True\n",
    "            \n",
    "        print('Domicilio not found')\n",
    "        return False\n",
    "    \n",
    "    def extract_CLAVE_DE_ELECTOR(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bCLAVE\\s+DE\\s+ELECTOR\\s+(\\S+)', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            # Check if the pattern matched\n",
    "            if match:\n",
    "                self.indx_ready.add(key + 2) #Index where the word Clave De ELECTOR is.\n",
    "\n",
    "                extracted_value = match.group(1)  # Get the first capturing group\n",
    "                self.data_f['clave_elector'] = extracted_value\n",
    "                self.indx_clv_elec = key\n",
    "                return True\n",
    "            \n",
    "        print('CLAVE DE ELECTOR not found')\n",
    "        return False\n",
    "    \n",
    "    def extract_EDO_MUNP_SECC(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern_edo = re.compile(r'\\b\\w*ESTA\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern_edo.search(line)\n",
    "            \n",
    "            # Print whether a match was found\n",
    "            if match:\n",
    "                self.indx_ready.add(key) #Index with the 3 values\n",
    "                \n",
    "                line_values = line.split(' ')\n",
    "                self.data_f['estado'] = line_values[1]\n",
    "                self.data_f['municipio'] = line_values[3]\n",
    "                self.data_f['seccion'] = line_values[5]\n",
    "\n",
    "    def extract_CURP_REGIS(self):\n",
    "\n",
    "        pattern = re.compile(r'\\b\\w*CUR\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                self.indx_ready.add(key) #Index with the CURP\n",
    "                line_data = self.text_struct[key].split(' ')\n",
    "\n",
    "                self.data_f['curp'] = line_data[1]\n",
    "\n",
    "                self.data_f['registro'] = line_data[-2]\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                return True\n",
    "        self.msgs.append({'detail':'CURP not found'})\n",
    "        return False\n",
    "\n",
    "    def extract_LOC_EMIS_VIGEN(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern_edo = re.compile(r'\\b\\w*LOCALIDAD\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern_edo.search(line)\n",
    "            \n",
    "            # Print whether a match was found\n",
    "            if match:\n",
    "                self.indx_ready.add(key) #Index with the 3 values\n",
    "\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['localidad'] = line_values[1]\n",
    "                except:\n",
    "                    self.msgs.append({'detail':'LOCALIDAD not found'})\n",
    "                    \n",
    "                try:\n",
    "                    self.data_f['municipio'] = line_values[3]\n",
    "                except:\n",
    "                    self.msgs.append({'detail':'SECCION not found'})\n",
    "\n",
    "                try:\n",
    "                    self.data_f['seccion'] = line_values[5]\n",
    "                except:\n",
    "                    self.msgs.append({'detail':'SECCION not found'})\n",
    "\n",
    "                return True\n",
    "            \n",
    "        self.msgs.append({'detail':'LOCALIDAD not found'})\n",
    "        return False\n",
    "    \n",
    "    def sinte(self):\n",
    "        data = []\n",
    "        count_found = 0\n",
    "        indx = 0\n",
    "        for key, value in self.data_f.items():\n",
    "\n",
    "            found = value != ''\n",
    "\n",
    "            item = {\n",
    "                'id': indx,\n",
    "                'key': key,\n",
    "                'value': value,\n",
    "                'found': found\n",
    "            }\n",
    "\n",
    "            data.append(item)\n",
    "\n",
    "            #Increment values found\n",
    "            if found:\n",
    "                count_found +=1\n",
    "\n",
    "            #Increment index value\n",
    "            indx +=1\n",
    "\n",
    "        if count_found !=0:\n",
    "            self.perc_found = np.round((count_found/len(self.data_f))*100)\n",
    "        \n",
    "        self.send_data = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    def calculate_perce(self):\n",
    "        perc_local = self.perc_found\n",
    "\n",
    "        graph = {\n",
    "            'values': [perc_local,100-perc_local],\n",
    "            'lables': ['',''],\n",
    "            'colors': ['#FDFEFE','#FDFEFE'],\n",
    "            'percentage': perc_local\n",
    "        }\n",
    "    \n",
    "        if perc_local >= 95:\n",
    "            graph['colors'][0] = '#2ECC71'\n",
    "\n",
    "        elif perc_local >= 75:\n",
    "            graph['colors'][0] = '#F4D03F'\n",
    "\n",
    "        elif perc_local >= 50:\n",
    "            graph['colors'][0] = '#F39C12'\n",
    "        else:\n",
    "            graph['colors'][0] = '#E74C3C'\n",
    "\n",
    "        self.graph_data = graph\n",
    "\n",
    "        return True\n",
    "\n",
    "    def start_finding(self):\n",
    "\n",
    "        self.extract_NOMBRE_NACIM_SEX()\n",
    "        self.extract_CLAVE_DE_ELECTOR()\n",
    "        if self.indx_clv_elec != -1:\n",
    "            self.extract_DOMICILIO()\n",
    "        self.extract_EDO_MUNP_SECC()\n",
    "        self.extract_CURP_REGIS()\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.extract_text_from_image()\n",
    "        self.structure_data()\n",
    "\n",
    "        self.start_finding()\n",
    "\n",
    "        self.sinte()\n",
    "        self.calculate_perce()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nombre': 'JUAN LUIS oe SAENZ ARMENDARIZ',\n",
       " 'domicilio': ' C HACIENDA DEL NOPAL 6527 FRACC HACIENDAS DEL VALLE 31217 CHIHUAHUA, CHIH.',\n",
       " 'clave_elector': 'SNARJN01091308H800',\n",
       " 'curp': 'SAAJO10913HCHNRNAS',\n",
       " 'registro': '2019',\n",
       " 'estado': '08',\n",
       " 'municipio': '019',\n",
       " 'seccion': '0805',\n",
       " 'localidad': '',\n",
       " 'emision': '',\n",
       " 'vigencia': '',\n",
       " 'nacimiento': '43/09/2001',\n",
       " 'sexo': 'H'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = ExtractData(img_path='image2.jpg')\n",
    "extract.execute()\n",
    "print(extract.msgs)\n",
    "extract.data_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11, 12, 13, 14, 20, 21}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract.indx_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '. £',\n",
       " 1: 'can',\n",
       " 2: 'Pie',\n",
       " 3: 'SD)',\n",
       " 4: 'Soap',\n",
       " 5: 'ter sy,',\n",
       " 6: 'rub 4 f',\n",
       " 7: 'k@sor',\n",
       " 8: 'S MEXICO INSTITUTO NACIONAL ELECTORAL',\n",
       " 9: 'CREDENCIAL PARA VOTAR ee',\n",
       " 10: 'ne ee ___ = ~',\n",
       " 11: 'NOMBRE FECHA DE NACIMIENTO',\n",
       " 12: 'SAENZ 43/09/2001',\n",
       " 13: 'ARMENDARIZ sexo’ H',\n",
       " 14: 'JUAN LUIS oe',\n",
       " 15: 'DOMICILIO',\n",
       " 16: 'C HACIENDA DEL NOPAL 6527',\n",
       " 17: 'FRACC HACIENDAS DEL VALLE 31217',\n",
       " 18: 'CHIHUAHUA, CHIH.',\n",
       " 19: 'CLAVE DE ELECTOR SNARJN01091308H800',\n",
       " 20: 'cure SAAJO10913HCHNRNAS = aXtoerecistro 2019 00',\n",
       " 21: 'estano 08 municiero 019 secon 0805 ~',\n",
       " 22: 'tocauoao 0001 emision 2019 vicenca 2029 » +',\n",
       " 23: 'feedreader ed edged'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract.text_struct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
