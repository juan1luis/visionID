{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import pytesseract as tess\n",
    "tess.pytesseract.tesseract_cmd = os.path.join(r'Tesseract-OCR\\tesseract.exe')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to Process the image and Extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData:\n",
    "    #Start the initial variables\n",
    "    def __init__(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        \n",
    "        #Store text found by tesseract\n",
    "        self.doc_text = ''\n",
    "        #Store the text as a dicc\n",
    "        self.text_struct = ''\n",
    "\n",
    "        #Due to the fied 'Domicilio' there may be a different lenght of rows, we use 'Clave Elector' as reference\n",
    "        self.indx_clv_elec = -1\n",
    "\n",
    "        self.send_data = []\n",
    "        self.perc_found = 0\n",
    "\n",
    "        self.graph_data = {}\n",
    "\n",
    "        # This is the data that we are looking for\n",
    "        self.data_f = {\n",
    "                'nombre': '',\n",
    "                'domicilio': '',\n",
    "                'clave_elector': '',\n",
    "                'curp': '',\n",
    "                'registro': '',\n",
    "                'estado': '',\n",
    "                'municipio': '',\n",
    "                'seccion': '',\n",
    "                'localidad': '',\n",
    "                'emision': '',\n",
    "                'vigencia': '',\n",
    "                'nacimiento': '',\n",
    "                'sexo': ''\n",
    "            }\n",
    "\n",
    "    def extract_text_from_image(self, croppe=False):\n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(self.img_path)\n",
    "\n",
    "        # In this section we wanna focus where the data is.\n",
    "        if croppe:\n",
    "            # Resize the image for better accuracy (optional)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply a median blur to reduce noise\n",
    "            gray_image = cv2.medianBlur(gray_image, 3)\n",
    "            \n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 2)\n",
    "            \n",
    "            \n",
    "            # Apply morphological operations to close gaps and reduce noise\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "            morph_image = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # Apply Canny edge detection\n",
    "            edges = cv2.Canny(morph_image, 50, 150)\n",
    "            \n",
    "            # Find contours on the edged image\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Initialize a variable to store the largest rectangle contour\n",
    "            largest_rect = None\n",
    "            largest_area = 0\n",
    "            \n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area < 1000:  # Filter out small contours by area\n",
    "                    continue\n",
    "\n",
    "                # Approximate the contour to a polygon\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                \n",
    "                # Check if the approximated contour has four points (rectangle)\n",
    "                if len(approx) == 4:\n",
    "                    if area > largest_area:\n",
    "                        largest_area = area\n",
    "                        largest_rect = approx\n",
    "            \n",
    "            \"\"\"# Draw all contours for visualization\n",
    "            contour_image = image.copy()\n",
    "            cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  # Draw all contours in green\n",
    "            \n",
    "            # Draw all rectangular contours\n",
    "            for contour in contours:\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                if len(approx) == 4:\n",
    "                    cv2.drawContours(contour_image, [approx], -1, (255, 0, 0), 2)  # Draw all rectangles in blue\n",
    "            \n",
    "            # Draw the largest rectangle contour in red\n",
    "            if largest_rect is not None:\n",
    "                cv2.drawContours(contour_image, [largest_rect], -1, (0, 0, 255), 2)  # Draw the largest rectangle in red\"\"\"\n",
    "\n",
    "\n",
    "            # If a rectangle was found then crop the image in that rectangle size\n",
    "            if largest_rect is not None:\n",
    "                x, y, w, h = cv2.boundingRect(largest_rect)\n",
    "                final_img_use = image[y:y+h, x:x+w]\n",
    "            else:\n",
    "                final_img_use = image\n",
    "        else:\n",
    "            #If we are not going to crop the image then we just use the original\n",
    "            final_img_use = image\n",
    "\n",
    "\n",
    "        cropped_image_re = cv2.resize(final_img_use, (0, 0), fx=1.8, fy=1.8)\n",
    "        \n",
    "        # Convert the cropped image to grayscale\n",
    "        gray_cropped = cv2.cvtColor(cropped_image_re, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply a median blur to reduce noise\n",
    "        gray_cropped = cv2.medianBlur(gray_cropped, 1)\n",
    "\n",
    "        # Apply binary thresholding\n",
    "        _, binary_image = cv2.threshold(gray_cropped, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Use Tesseract to extract text\n",
    "        text = tess.image_to_string(binary_image)\n",
    "        \n",
    "        #Finally store the text\n",
    "        self.doc_text = text\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def structure_data(self):\n",
    "        #We structure the data found in the image to have better manipulation.\n",
    "        lines = self.doc_text.split('\\n')\n",
    "        data = {}\n",
    "        count = 0\n",
    "        for i in range(len(lines)):\n",
    "\n",
    "            if lines[i] != '' and len(lines[i]) >= 3:\n",
    "                data[count] = lines[i]\n",
    "                count += 1\n",
    "\n",
    "        self.text_struct = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    #Find Data   \n",
    "    def num_from_str(self, string):\n",
    "        # Find all numeric sequences in the text\n",
    "        numbers = re.findall(r'\\d+', string)\n",
    "        \n",
    "        # Join all numbers into a single string\n",
    "        concatenated_number = ''.join(numbers)\n",
    "        \n",
    "        return concatenated_number\n",
    "\n",
    "    def extract_NOMBRE_NACIM_SEX(self):\n",
    "        #We stablish the pattern of the data we are looking for\n",
    "        pattern = re.compile(r'\\b\\w*NOMBRE\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        #Then we itarete through the structured text.\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "            # Check if the pattern matched\n",
    "            if match:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    line_data_1 = self.text_struct[key+1].split(' ')\n",
    "                    last_name_1 = line_data_1[0]\n",
    "\n",
    "                    #The birth date is in the same line as the first last name\n",
    "                    self.data_f['nacimiento'] = line_data_1[1]\n",
    "\n",
    "                    line_data_2 = self.text_struct[key + 2].split(' ')\n",
    "                    last_name_2 = line_data_2[0]\n",
    "\n",
    "                    #The sex is in the same line as the second last name\n",
    "                    if len(line_data_2) >= 3:\n",
    "                        \n",
    "                        self.data_f['sexo'] = line_data_2[2]\n",
    "                    \n",
    "                    raw_name = self.text_struct[key + 3].split(' ')\n",
    "\n",
    "                    filter_name = [part for part in raw_name if len(part) > 1]\n",
    "            \n",
    "                    # Join the filtered words into a single string\n",
    "                    name = ' '.join(filter_name)\n",
    "                    \n",
    "                    self.data_f['nombre'] = f'{name} {last_name_1} {last_name_2}'\n",
    "                    return True\n",
    "                except:\n",
    "                    return False\n",
    "\n",
    "    def extract_DOMICILIO(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bDOMIC\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, value in self.text_struct.items():\n",
    "            if pattern.search(value):\n",
    "\n",
    "                indx_domici = key\n",
    "                direc = ''\n",
    "                for key_2, value in self.text_struct.items():\n",
    "                    if indx_domici < key_2 < self.indx_clv_elec:\n",
    "                        direc += ' ' + value\n",
    "\n",
    "                self.data_f['domicilio'] = direc\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def extract_CLAVE_DE_ELECTOR(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bCLAVE\\s+DE\\s+ELECTOR\\s+(\\S+)', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                try:\n",
    "                    extracted_value = match.group(1)  # Get the first capturing group\n",
    "                    self.data_f['clave_elector'] = extracted_value\n",
    "                except:\n",
    "                    pass\n",
    "                self.indx_clv_elec = key\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def extract_EDO_MUNP_SECC(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern_edo = re.compile(r'\\b\\w*ESTA\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern_edo.search(line)\n",
    "            \n",
    "            # Print if a match was found\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['estado'] = self.num_from_str(line_values[1])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['municipio'] = self.num_from_str(line_values[3])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['seccion'] = self.num_from_str(line_values[5])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def extract_CURP_REGIS(self):\n",
    "\n",
    "        pattern = re.compile(r'\\b\\w*CUR\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                line_data = self.text_struct[key].split(' ')\n",
    "                try:\n",
    "                    self.data_f['curp'] = line_data[1]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['registro'] = line_data[-2]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def extract_LOC_EMIS_VIGEN(self):\n",
    "\n",
    "        pattern =  re.compile(r'\\b\\w*(?:LOCALIDAD|EMISION|VIGENCIA)\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern.findall(line)\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['localidad'] = line_values[1]\n",
    "                except:\n",
    "                    pass                    \n",
    "                try:\n",
    "                    self.data_f['emision'] = line_values[3]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['vigencia'] = line_values[5]\n",
    "                except:\n",
    "                    pass\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def sinte(self):\n",
    "        data = []\n",
    "        count_found = 0\n",
    "        indx = 0\n",
    "        for key, value in self.data_f.items():\n",
    "\n",
    "            found = value != ''\n",
    "\n",
    "            item = {\n",
    "                'id': indx,\n",
    "                'key': key,\n",
    "                'value': value,\n",
    "                'found': found\n",
    "            }\n",
    "\n",
    "            data.append(item)\n",
    "\n",
    "            #Increment values found\n",
    "            if found:\n",
    "                count_found +=1\n",
    "\n",
    "            #Increment index value\n",
    "            indx +=1\n",
    "\n",
    "        if count_found !=0:\n",
    "            #Calculate the percentage of data found\n",
    "            self.perc_found = np.round((count_found/len(self.data_f))*100)\n",
    "        \n",
    "        self.send_data = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    def calculate_perce(self):\n",
    "        perc_local = self.perc_found\n",
    "\n",
    "        graph = {\n",
    "            'values': [perc_local,100-perc_local],\n",
    "            'lables': ['',''],\n",
    "            'colors': ['#FDFEFE','#FDFEFE'],\n",
    "            'percentage': perc_local\n",
    "        }\n",
    "        #Give a color to the graph according to the percentage\n",
    "        if perc_local >= 95:\n",
    "            graph['colors'][0] = '#2ECC71'\n",
    "\n",
    "        elif perc_local >= 75:\n",
    "            graph['colors'][0] = '#F4D03F'\n",
    "\n",
    "        elif perc_local >= 50:\n",
    "            graph['colors'][0] = '#F39C12'\n",
    "        else:\n",
    "            graph['colors'][0] = '#E74C3C'\n",
    "\n",
    "        self.graph_data = graph\n",
    "\n",
    "        return True\n",
    "\n",
    "    def start_finding(self):\n",
    "        # Just go through each method to find the data\n",
    "        self.extract_NOMBRE_NACIM_SEX()\n",
    "        self.extract_CLAVE_DE_ELECTOR()\n",
    "        if self.indx_clv_elec != -1:\n",
    "            self.extract_DOMICILIO()\n",
    "        self.extract_EDO_MUNP_SECC()\n",
    "        self.extract_CURP_REGIS()\n",
    "        self.extract_LOC_EMIS_VIGEN()\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.extract_text_from_image(croppe=True)\n",
    "        self.structure_data()\n",
    "        #It`s possible that the cropped part went wrong due to different sizing, so if we don't find enough data we are going to repeat the process but without cropping.\n",
    "        if len(self.text_struct) <= 5:\n",
    "            self.extract_text_from_image()\n",
    "            self.structure_data()\n",
    "            \n",
    "        #Now that we have the data we start looking for the fields.\n",
    "        self.start_finding()\n",
    "\n",
    "        self.sinte()\n",
    "        self.calculate_perce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here you can Execute the Method\n",
    "Don't forget to change the path of the image to where yours is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = ExtractData(img_path='image2.jpg')\n",
    "extract.execute()\n",
    "extract.data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract.text_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the example of how to request data from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the API endpoint\n",
    "url = 'https://datalegen.com/api-request'\n",
    "\n",
    "# Path to the image file you want to upload\n",
    "image_path = 'image2.jpg'\n",
    "\n",
    "# Prepare the file to be sent in the POST request\n",
    "files = {'image_file': open(image_path, 'rb')}\n",
    "\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, files=files)\n",
    "\n",
    "try:\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Print the response JSON data\n",
    "        print('Response data:', response.json())\n",
    "    else:\n",
    "        print('Error:', response.status_code, response.json())\n",
    "except Exception as e:\n",
    "    print('An error occurred:', str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
