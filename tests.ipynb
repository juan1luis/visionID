{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract as tess\n",
    "tess.pytesseract.tesseract_cmd = os.path.join(r'Tesseract-OCR\\tesseract.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData:\n",
    "\n",
    "    def __init__(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        \n",
    "        self.doc_text = ''\n",
    "        self.text_struct = ''\n",
    "        self.indx_clv_elec = -1\n",
    "\n",
    "        self.msgs = []\n",
    "\n",
    "        self.send_data = []\n",
    "        self.perc_found = 0\n",
    "\n",
    "        self.graph_data = {}\n",
    "\n",
    "        self.data_f = {\n",
    "                'nombre': '',\n",
    "                'domicilio': '',\n",
    "                'clave_elector': '',\n",
    "                'curp': '',\n",
    "                'registro': '',\n",
    "                'estado': '',\n",
    "                'municipio': '',\n",
    "                'seccion': '',\n",
    "                'localidad': '',\n",
    "                'emision': '',\n",
    "                'vigencia': '',\n",
    "                'nacimiento': '',\n",
    "                'sexo': ''\n",
    "            }\n",
    "\n",
    "    \n",
    "    def extract_text_from_image(self, croppe=False):\n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(self.img_path)\n",
    "        \n",
    "        if croppe:\n",
    "            # Resize the image for better accuracy (optional)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply a median blur to reduce noise\n",
    "            gray_image = cv2.medianBlur(gray_image, 3)\n",
    "            \n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 2)\n",
    "            \n",
    "            #cv2.imshow('adaptive_thresh', adaptive_thresh)\n",
    "            \n",
    "            # Apply morphological operations to close gaps and reduce noise\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "            morph_image = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            #cv2.imshow('morph_image', morph_image)\n",
    "\n",
    "            # Apply Canny edge detection\n",
    "            edges = cv2.Canny(morph_image, 50, 150)\n",
    "            \n",
    "            # Find contours in the edged image\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Initialize a variable to store the largest rectangle contour\n",
    "            largest_rect = None\n",
    "            largest_area = 0\n",
    "            \n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area < 1000:  # Filter out small contours by area\n",
    "                    continue\n",
    "\n",
    "                # Approximate the contour to a polygon\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                \n",
    "                # Check if the approximated contour has four points (rectangle)\n",
    "                if len(approx) == 4:\n",
    "                    if area > largest_area:\n",
    "                        largest_area = area\n",
    "                        largest_rect = approx\n",
    "            \n",
    "            # Draw all contours for visualization\n",
    "            contour_image = image.copy()\n",
    "            cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  # Draw all contours in green\n",
    "            \n",
    "            # Draw all rectangular contours\n",
    "            for contour in contours:\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                if len(approx) == 4:\n",
    "                    cv2.drawContours(contour_image, [approx], -1, (255, 0, 0), 2)  # Draw all rectangles in blue\n",
    "            \n",
    "            # Draw the largest rectangle contour in red\n",
    "            if largest_rect is not None:\n",
    "                cv2.drawContours(contour_image, [largest_rect], -1, (0, 0, 255), 2)  # Draw the largest rectangle in red\n",
    "\n",
    "            # Display the image with contours\n",
    "\n",
    "            # If a rectangle was found, crop the image to that rectangle\n",
    "            if largest_rect is not None:\n",
    "                x, y, w, h = cv2.boundingRect(largest_rect)\n",
    "                final_img_use = image[y:y+h, x:x+w]\n",
    "            else:\n",
    "                final_img_use = image\n",
    "        else:\n",
    "            final_img_use = image\n",
    "\n",
    "        #cv2.imshow('cropped_image', cropped_image)\n",
    "\n",
    "        cropped_image_re = cv2.resize(final_img_use, (0, 0), fx=1.8, fy=1.8)\n",
    "        \n",
    "        # Convert the cropped image to grayscale\n",
    "        gray_cropped = cv2.cvtColor(cropped_image_re, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.imshow('gray_cropped', gray_cropped)\n",
    "\n",
    "        # Apply a median blur to reduce noise\n",
    "        gray_cropped = cv2.medianBlur(gray_cropped, 1)\n",
    "\n",
    "        # Apply binary thresholding\n",
    "        _, binary_image = cv2.threshold(gray_cropped, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        #cv2.imshow('binary_image', binary_image)\n",
    "\n",
    "        \n",
    "        # Use Tesseract to extract text\n",
    "        text = tess.image_to_string(binary_image)\n",
    "        \n",
    "\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        self.doc_text = text\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def structure_data(self):\n",
    "\n",
    "        lines = self.doc_text.split('\\n')\n",
    "        data = {}\n",
    "        count = 0\n",
    "        for i in range(len(lines)):\n",
    "\n",
    "            if lines[i] != '' and len(lines[i]) >= 3:\n",
    "                data[count] = lines[i]\n",
    "                count += 1\n",
    "\n",
    "        self.text_struct = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    #Find Data   \n",
    "    def num_from_str(self, string):\n",
    "        # Find all numeric sequences in the text\n",
    "        numbers = re.findall(r'\\d+', string)\n",
    "        \n",
    "        # Join all numbers into a single string\n",
    "        concatenated_number = ''.join(numbers)\n",
    "        \n",
    "        return concatenated_number\n",
    "\n",
    "    def extract_NOMBRE_NACIM_SEX(self):\n",
    "        pattern = re.compile(r'\\b\\w*NOMBRE\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    line_data_1 = self.text_struct[key+1].split(' ')\n",
    "                    last_name_1 = line_data_1[0]\n",
    "\n",
    "                    #The born date is in the same line as the first last name\n",
    "                    self.data_f['nacimiento'] = line_data_1[1]\n",
    "\n",
    "                    line_data_2 = self.text_struct[key + 2].split(' ')\n",
    "                    last_name_2 = line_data_2[0]\n",
    "\n",
    "                    #The sex is in the same line as the second last name\n",
    "                    if len(line_data_2) >= 3:\n",
    "                        \n",
    "                        self.data_f['sexo'] = line_data_2[2]\n",
    "                    \n",
    "                    raw_name = self.text_struct[key + 3].split(' ')\n",
    "\n",
    "                    filter_name = [part for part in raw_name if len(part) > 1]\n",
    "            \n",
    "                    # Join the filtered words into a single string\n",
    "                    name = ' '.join(filter_name)\n",
    "                    \n",
    "                    self.data_f['nombre'] = f'{name} {last_name_1} {last_name_2}'\n",
    "                    return True\n",
    "                except:\n",
    "                    return False\n",
    "\n",
    "    def extract_DOMICILIO(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bDOMIC\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, value in self.text_struct.items():\n",
    "            if pattern.search(value):\n",
    "\n",
    "                indx_domici = key\n",
    "                direc = ''\n",
    "                for key_2, value in self.text_struct.items():\n",
    "                    if indx_domici < key_2 < self.indx_clv_elec:\n",
    "                        direc += ' ' + value\n",
    "\n",
    "                self.data_f['domicilio'] = direc\n",
    "                return True\n",
    "            \n",
    "        print('Domicilio not found')\n",
    "        return False\n",
    "    \n",
    "    def extract_CLAVE_DE_ELECTOR(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bCLAVE\\s+DE\\s+ELECTOR\\s+(\\S+)', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            # Check if the pattern matched\n",
    "            if match:\n",
    "                try:\n",
    "                    extracted_value = match.group(1)  # Get the first capturing group\n",
    "                    self.data_f['clave_elector'] = extracted_value\n",
    "                except:\n",
    "                    pass\n",
    "                self.indx_clv_elec = key\n",
    "                return True\n",
    "            \n",
    "        print('CLAVE DE ELECTOR not found')\n",
    "        return False\n",
    "    \n",
    "    def extract_EDO_MUNP_SECC(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern_edo = re.compile(r'\\b\\w*ESTA\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern_edo.search(line)\n",
    "            \n",
    "            # Print whether a match was found\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['estado'] = self.num_from_str(line_values[1])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['municipio'] = self.num_from_str(line_values[3])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['seccion'] = self.num_from_str(line_values[5])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def extract_CURP_REGIS(self):\n",
    "\n",
    "        pattern = re.compile(r'\\b\\w*CUR\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                line_data = self.text_struct[key].split(' ')\n",
    "                try:\n",
    "                    self.data_f['curp'] = line_data[1]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['registro'] = line_data[-2]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                return True\n",
    "        self.msgs.append({'detail':'CURP not found'})\n",
    "        return False\n",
    "\n",
    "    def extract_LOC_EMIS_VIGEN(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern =  re.compile(r'\\b\\w*(?:LOCALIDAD|EMISION|VIGENCIA)\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern.findall(line)\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                print(line_values)\n",
    "                try:\n",
    "                    self.data_f['localidad'] = line_values[1]\n",
    "                except:\n",
    "                    pass                    \n",
    "                try:\n",
    "                    self.data_f['emision'] = line_values[3]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['vigencia'] = line_values[5]\n",
    "                except:\n",
    "                    pass\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def sinte(self):\n",
    "        data = []\n",
    "        count_found = 0\n",
    "        indx = 0\n",
    "        for key, value in self.data_f.items():\n",
    "\n",
    "            found = value != ''\n",
    "\n",
    "            item = {\n",
    "                'id': indx,\n",
    "                'key': key,\n",
    "                'value': value,\n",
    "                'found': found\n",
    "            }\n",
    "\n",
    "            data.append(item)\n",
    "\n",
    "            #Increment values found\n",
    "            if found:\n",
    "                count_found +=1\n",
    "\n",
    "            #Increment index value\n",
    "            indx +=1\n",
    "\n",
    "        if count_found !=0:\n",
    "            self.perc_found = np.round((count_found/len(self.data_f))*100)\n",
    "        \n",
    "        self.send_data = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    def calculate_perce(self):\n",
    "        perc_local = self.perc_found\n",
    "\n",
    "        graph = {\n",
    "            'values': [perc_local,100-perc_local],\n",
    "            'lables': ['',''],\n",
    "            'colors': ['#FDFEFE','#FDFEFE'],\n",
    "            'percentage': perc_local\n",
    "        }\n",
    "    \n",
    "        if perc_local >= 95:\n",
    "            graph['colors'][0] = '#2ECC71'\n",
    "\n",
    "        elif perc_local >= 75:\n",
    "            graph['colors'][0] = '#F4D03F'\n",
    "\n",
    "        elif perc_local >= 50:\n",
    "            graph['colors'][0] = '#F39C12'\n",
    "        else:\n",
    "            graph['colors'][0] = '#E74C3C'\n",
    "\n",
    "        self.graph_data = graph\n",
    "\n",
    "        return True\n",
    "\n",
    "    def start_finding(self):\n",
    "\n",
    "        self.extract_NOMBRE_NACIM_SEX()\n",
    "        self.extract_CLAVE_DE_ELECTOR()\n",
    "        if self.indx_clv_elec != -1:\n",
    "            self.extract_DOMICILIO()\n",
    "        self.extract_EDO_MUNP_SECC()\n",
    "        self.extract_CURP_REGIS()\n",
    "        self.extract_LOC_EMIS_VIGEN()\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.extract_text_from_image(croppe=True)\n",
    "        self.structure_data()\n",
    "        #Is possible the cropped went wrong due to diferent sizing, so if we don't find  enought data we are going to repeat but with out cropping.\n",
    "        if len(self.text_struct) <= 5:\n",
    "            self.extract_text_from_image()\n",
    "            self.structure_data()\n",
    "        #Now that we have the data we start looking the fields.\n",
    "        self.start_finding()\n",
    "\n",
    "        self.sinte()\n",
    "        self.calculate_perce()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Locaupap', '0001', 'emision', '2019-4']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nombre': 'JUAN LUIS SAENZ ARMENDARIZ',\n",
       " 'domicilio': ' C HACIENDA DEL NOPAL 6527 FRACC HACIENDAS DEL VALLE 31217 CHIHUAHUA, CHIH.',\n",
       " 'clave_elector': 'SNARJN01091308H800',\n",
       " 'curp': 'SAAJO010913HCHNRNA6',\n",
       " 'registro': '019',\n",
       " 'estado': '08',\n",
       " 'municipio': '019',\n",
       " 'seccion': '0805',\n",
       " 'localidad': '0001',\n",
       " 'emision': '2019-4',\n",
       " 'vigencia': '',\n",
       " 'nacimiento': '1',\n",
       " 'sexo': ''}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = ExtractData(img_path='image6.jpg')\n",
    "extract.execute()\n",
    "extract.data_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'INSTITUTO NACIONAL ELECTORAL',\n",
       " 1: 'MEXICO GREDENCIAL PARA VOTAR od',\n",
       " 2: 'NOMBRE FECHA DE NACIMIENTO',\n",
       " 3: 'SAENZ 1 3109/2005',\n",
       " 4: 'ARMENDARIZ',\n",
       " 5: 'JUAN LUIS',\n",
       " 6: 'DOMICILIO',\n",
       " 7: 'C HACIENDA DEL NOPAL 6527',\n",
       " 8: 'FRACC HACIENDAS DEL VALLE 31217',\n",
       " 9: 'CHIHUAHUA, CHIH.',\n",
       " 10: 'CLAVE DE ELECTOR SNARJN01091308H800',\n",
       " 11: 'curp SAAJO010913HCHNRNA6 \"ARG DERECISTAO 019 0',\n",
       " 12: 'estapo 08 municipio 019 SECOION 0805 .',\n",
       " 13: 'Locaupap 0001 emision 2019-4',\n",
       " 14: 'ble fetefareraresererarererara so'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract.text_struct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
