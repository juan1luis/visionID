{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import pytesseract as tess\n",
    "tess.pytesseract.tesseract_cmd = os.path.join(r'Tesseract-OCR\\tesseract.exe')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to Process the image and Extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData:\n",
    "    #Start the initial variables\n",
    "    def __init__(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        \n",
    "        #Store text finded by tesserct\n",
    "        self.doc_text = ''\n",
    "        #Store the text as a dicc\n",
    "        self.text_struct = ''\n",
    "\n",
    "        #Due to the fied 'Domicilio' may diferent lenght of rows we use 'Clave Elector' as reference\n",
    "        self.indx_clv_elec = -1\n",
    "\n",
    "        self.send_data = []\n",
    "        self.perc_found = 0\n",
    "\n",
    "        self.graph_data = {}\n",
    "\n",
    "        # This is the data that we are looking for\n",
    "        self.data_f = {\n",
    "                'nombre': '',\n",
    "                'domicilio': '',\n",
    "                'clave_elector': '',\n",
    "                'curp': '',\n",
    "                'registro': '',\n",
    "                'estado': '',\n",
    "                'municipio': '',\n",
    "                'seccion': '',\n",
    "                'localidad': '',\n",
    "                'emision': '',\n",
    "                'vigencia': '',\n",
    "                'nacimiento': '',\n",
    "                'sexo': ''\n",
    "            }\n",
    "\n",
    "    def extract_text_from_image(self, croppe=False):\n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(self.img_path)\n",
    "\n",
    "        # In this section we are looking to focus where the data is.\n",
    "        if croppe:\n",
    "            # Resize the image for better accuracy (optional)\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply a median blur to reduce noise\n",
    "            gray_image = cv2.medianBlur(gray_image, 3)\n",
    "            \n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 2)\n",
    "            \n",
    "            \n",
    "            # Apply morphological operations to close gaps and reduce noise\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "            morph_image = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # Apply Canny edge detection\n",
    "            edges = cv2.Canny(morph_image, 50, 150)\n",
    "            \n",
    "            # Find contours in the edged image\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Initialize a variable to store the largest rectangle contour\n",
    "            largest_rect = None\n",
    "            largest_area = 0\n",
    "            \n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area < 1000:  # Filter out small contours by area\n",
    "                    continue\n",
    "\n",
    "                # Approximate the contour to a polygon\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                \n",
    "                # Check if the approximated contour has four points (rectangle)\n",
    "                if len(approx) == 4:\n",
    "                    if area > largest_area:\n",
    "                        largest_area = area\n",
    "                        largest_rect = approx\n",
    "            \n",
    "            \"\"\"# Draw all contours for visualization\n",
    "            contour_image = image.copy()\n",
    "            cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  # Draw all contours in green\n",
    "            \n",
    "            # Draw all rectangular contours\n",
    "            for contour in contours:\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                if len(approx) == 4:\n",
    "                    cv2.drawContours(contour_image, [approx], -1, (255, 0, 0), 2)  # Draw all rectangles in blue\n",
    "            \n",
    "            # Draw the largest rectangle contour in red\n",
    "            if largest_rect is not None:\n",
    "                cv2.drawContours(contour_image, [largest_rect], -1, (0, 0, 255), 2)  # Draw the largest rectangle in red\"\"\"\n",
    "\n",
    "\n",
    "            # If a rectangle was found crop the image to that rectangle\n",
    "            if largest_rect is not None:\n",
    "                x, y, w, h = cv2.boundingRect(largest_rect)\n",
    "                final_img_use = image[y:y+h, x:x+w]\n",
    "            else:\n",
    "                final_img_use = image\n",
    "        else:\n",
    "            #If were are not going to cropped the image just use the original\n",
    "            final_img_use = image\n",
    "\n",
    "\n",
    "        cropped_image_re = cv2.resize(final_img_use, (0, 0), fx=1.8, fy=1.8)\n",
    "        \n",
    "        # Convert the cropped image to grayscale\n",
    "        gray_cropped = cv2.cvtColor(cropped_image_re, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply a median blur to reduce noise\n",
    "        gray_cropped = cv2.medianBlur(gray_cropped, 1)\n",
    "\n",
    "        # Apply binary thresholding\n",
    "        _, binary_image = cv2.threshold(gray_cropped, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Use Tesseract to extract text\n",
    "        text = tess.image_to_string(binary_image)\n",
    "        \n",
    "        #Finally store the text\n",
    "        self.doc_text = text\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def structure_data(self):\n",
    "        #We struct the data found in the image to better manipulation.\n",
    "        lines = self.doc_text.split('\\n')\n",
    "        data = {}\n",
    "        count = 0\n",
    "        for i in range(len(lines)):\n",
    "\n",
    "            if lines[i] != '' and len(lines[i]) >= 3:\n",
    "                data[count] = lines[i]\n",
    "                count += 1\n",
    "\n",
    "        self.text_struct = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    #Find Data   \n",
    "    def num_from_str(self, string):\n",
    "        # Find all numeric sequences in the text\n",
    "        numbers = re.findall(r'\\d+', string)\n",
    "        \n",
    "        # Join all numbers into a single string\n",
    "        concatenated_number = ''.join(numbers)\n",
    "        \n",
    "        return concatenated_number\n",
    "\n",
    "    def extract_NOMBRE_NACIM_SEX(self):\n",
    "        #We stablish the pattern of the data we are looking for\n",
    "        pattern = re.compile(r'\\b\\w*NOMBRE\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        #Then we itarete trought the structured text.\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "            # Check if the pattern matched\n",
    "            if match:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    line_data_1 = self.text_struct[key+1].split(' ')\n",
    "                    last_name_1 = line_data_1[0]\n",
    "\n",
    "                    #The born date is in the same line as the first last name\n",
    "                    self.data_f['nacimiento'] = line_data_1[1]\n",
    "\n",
    "                    line_data_2 = self.text_struct[key + 2].split(' ')\n",
    "                    last_name_2 = line_data_2[0]\n",
    "\n",
    "                    #The sex is in the same line as the second last name\n",
    "                    if len(line_data_2) >= 3:\n",
    "                        \n",
    "                        self.data_f['sexo'] = line_data_2[2]\n",
    "                    \n",
    "                    raw_name = self.text_struct[key + 3].split(' ')\n",
    "\n",
    "                    filter_name = [part for part in raw_name if len(part) > 1]\n",
    "            \n",
    "                    # Join the filtered words into a single string\n",
    "                    name = ' '.join(filter_name)\n",
    "                    \n",
    "                    self.data_f['nombre'] = f'{name} {last_name_1} {last_name_2}'\n",
    "                    return True\n",
    "                except:\n",
    "                    return False\n",
    "\n",
    "    def extract_DOMICILIO(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bDOMIC\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, value in self.text_struct.items():\n",
    "            if pattern.search(value):\n",
    "\n",
    "                indx_domici = key\n",
    "                direc = ''\n",
    "                for key_2, value in self.text_struct.items():\n",
    "                    if indx_domici < key_2 < self.indx_clv_elec:\n",
    "                        direc += ' ' + value\n",
    "\n",
    "                self.data_f['domicilio'] = direc\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def extract_CLAVE_DE_ELECTOR(self):\n",
    "\n",
    "        pattern = re.compile(r'\\bCLAVE\\s+DE\\s+ELECTOR\\s+(\\S+)', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                try:\n",
    "                    extracted_value = match.group(1)  # Get the first capturing group\n",
    "                    self.data_f['clave_elector'] = extracted_value\n",
    "                except:\n",
    "                    pass\n",
    "                self.indx_clv_elec = key\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def extract_EDO_MUNP_SECC(self):\n",
    "\n",
    "        # Pattern to match any word containing 'ESTADO'\n",
    "        pattern_edo = re.compile(r'\\b\\w*ESTA\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        # Iterate over the lines in self.text_struct\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern_edo.search(line)\n",
    "            \n",
    "            # Print whether a match was found\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['estado'] = self.num_from_str(line_values[1])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['municipio'] = self.num_from_str(line_values[3])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['seccion'] = self.num_from_str(line_values[5])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def extract_CURP_REGIS(self):\n",
    "\n",
    "        pattern = re.compile(r'\\b\\w*CUR\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "\n",
    "            match = pattern.search(line)\n",
    "\n",
    "            if match:\n",
    "                line_data = self.text_struct[key].split(' ')\n",
    "                try:\n",
    "                    self.data_f['curp'] = line_data[1]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['registro'] = line_data[-2]\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def extract_LOC_EMIS_VIGEN(self):\n",
    "\n",
    "        pattern =  re.compile(r'\\b\\w*(?:LOCALIDAD|EMISION|VIGENCIA)\\w*\\b', re.IGNORECASE)\n",
    "\n",
    "        for key, line in self.text_struct.items():\n",
    "            \n",
    "            # Search for the pattern in the line\n",
    "            match = pattern.findall(line)\n",
    "            if match:\n",
    "                line_values = line.split(' ')\n",
    "                try:\n",
    "                    self.data_f['localidad'] = line_values[1]\n",
    "                except:\n",
    "                    pass                    \n",
    "                try:\n",
    "                    self.data_f['emision'] = line_values[3]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    self.data_f['vigencia'] = line_values[5]\n",
    "                except:\n",
    "                    pass\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def sinte(self):\n",
    "        data = []\n",
    "        count_found = 0\n",
    "        indx = 0\n",
    "        for key, value in self.data_f.items():\n",
    "\n",
    "            found = value != ''\n",
    "\n",
    "            item = {\n",
    "                'id': indx,\n",
    "                'key': key,\n",
    "                'value': value,\n",
    "                'found': found\n",
    "            }\n",
    "\n",
    "            data.append(item)\n",
    "\n",
    "            #Increment values found\n",
    "            if found:\n",
    "                count_found +=1\n",
    "\n",
    "            #Increment index value\n",
    "            indx +=1\n",
    "\n",
    "        if count_found !=0:\n",
    "            #Calculate the percentage of data found\n",
    "            self.perc_found = np.round((count_found/len(self.data_f))*100)\n",
    "        \n",
    "        self.send_data = data\n",
    "\n",
    "        return True\n",
    "\n",
    "    def calculate_perce(self):\n",
    "        perc_local = self.perc_found\n",
    "\n",
    "        graph = {\n",
    "            'values': [perc_local,100-perc_local],\n",
    "            'lables': ['',''],\n",
    "            'colors': ['#FDFEFE','#FDFEFE'],\n",
    "            'percentage': perc_local\n",
    "        }\n",
    "        #Give a color to the graph acording the percentage\n",
    "        if perc_local >= 95:\n",
    "            graph['colors'][0] = '#2ECC71'\n",
    "\n",
    "        elif perc_local >= 75:\n",
    "            graph['colors'][0] = '#F4D03F'\n",
    "\n",
    "        elif perc_local >= 50:\n",
    "            graph['colors'][0] = '#F39C12'\n",
    "        else:\n",
    "            graph['colors'][0] = '#E74C3C'\n",
    "\n",
    "        self.graph_data = graph\n",
    "\n",
    "        return True\n",
    "\n",
    "    def start_finding(self):\n",
    "        # Just go trouhgt each method to find the data\n",
    "        self.extract_NOMBRE_NACIM_SEX()\n",
    "        self.extract_CLAVE_DE_ELECTOR()\n",
    "        if self.indx_clv_elec != -1:\n",
    "            self.extract_DOMICILIO()\n",
    "        self.extract_EDO_MUNP_SECC()\n",
    "        self.extract_CURP_REGIS()\n",
    "        self.extract_LOC_EMIS_VIGEN()\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.extract_text_from_image(croppe=True)\n",
    "        self.structure_data()\n",
    "        #Is possible the cropped went wrong due to diferent sizing, so if we don't find  enought data we are going to repeat but with out cropping.\n",
    "        if len(self.text_struct) <= 5:\n",
    "            self.extract_text_from_image()\n",
    "            self.structure_data()\n",
    "        #Now that we have the data we start looking the fields.\n",
    "        self.start_finding()\n",
    "\n",
    "        self.sinte()\n",
    "        self.calculate_perce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here you can Execute the Method\n",
    "Don't for get to change the path of the image to where is yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tocauoao', '0001', 'emision', '2019', 'vicenca', '2029', '»', '+']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nombre': 'JUAN LUIS oe SAENZ ARMENDARIZ',\n",
       " 'domicilio': ' C HACIENDA DEL NOPAL 6527 FRACC HACIENDAS DEL VALLE 31217 CHIHUAHUA, CHIH.',\n",
       " 'clave_elector': 'SNARJN01091308H800',\n",
       " 'curp': 'SAAJO10913HCHNRNAS',\n",
       " 'registro': '2019',\n",
       " 'estado': '08',\n",
       " 'municipio': '019',\n",
       " 'seccion': '0805',\n",
       " 'localidad': '0001',\n",
       " 'emision': '2019',\n",
       " 'vigencia': '2029',\n",
       " 'nacimiento': '43/09/2001',\n",
       " 'sexo': 'H'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = ExtractData(img_path='image2.jpg')\n",
    "extract.execute()\n",
    "extract.data_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract.text_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the example of how to can request data to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response data: {'data_extracted': {'0': '. £', '1': 'can', '2': 'Pie', '3': 'SD)', '4': 'Soap', '5': 'ter sy,', '6': 'rub 4 f', '7': 'k@sor', '8': 'S MEXICO INSTITUTO NACIONAL ELECTORAL', '9': 'CREDENCIAL PARA VOTAR ee', '10': 'ne ee ___ = ~', '11': 'NOMBRE FECHA DE NACIMIENTO', '12': 'SAENZ 43/09/2001', '13': 'ARMENDARIZ sexo’ H', '14': 'JUAN LUIS oe', '15': 'DOMICILIO', '16': 'C HACIENDA DEL NOPAL 6527', '17': 'FRACC HACIENDAS DEL VALLE 31217', '18': 'CHIHUAHUA, CHIH.', '19': 'CLAVE DE ELECTOR SNARJN01091308H800', '20': 'cure SAAJO10913HCHNRNAS = aXtoerecistro 2019 00', '21': 'estano 08 municiero 019 secon 0805 ~', '22': 'tocauoao 0001 emision 2019 vicenca 2029 » +', '23': 'feedreader ed edged'}, 'graph_data': {'colors': ['#2ECC71', '#FDFEFE'], 'lables': ['', ''], 'percentage': 100.0, 'values': [100.0, 0.0]}, 'img_path': 'img_worked/20240726151006image2.jpg', 'raw_data': {'clave_elector': 'SNARJN01091308H800', 'curp': 'SAAJO10913HCHNRNAS', 'domicilio': ' C HACIENDA DEL NOPAL 6527 FRACC HACIENDAS DEL VALLE 31217 CHIHUAHUA, CHIH.', 'emision': '2019', 'estado': '08', 'localidad': '0001', 'municipio': '019', 'nacimiento': '43/09/2001', 'nombre': 'JUAN LUIS oe SAENZ ARMENDARIZ', 'registro': '2019', 'seccion': '0805', 'sexo': 'H', 'vigencia': '2029'}, 'structured_data': [{'found': True, 'id': 0, 'key': 'nombre', 'value': 'JUAN LUIS oe SAENZ ARMENDARIZ'}, {'found': True, 'id': 1, 'key': 'domicilio', 'value': ' C HACIENDA DEL NOPAL 6527 FRACC HACIENDAS DEL VALLE 31217 CHIHUAHUA, CHIH.'}, {'found': True, 'id': 2, 'key': 'clave_elector', 'value': 'SNARJN01091308H800'}, {'found': True, 'id': 3, 'key': 'curp', 'value': 'SAAJO10913HCHNRNAS'}, {'found': True, 'id': 4, 'key': 'registro', 'value': '2019'}, {'found': True, 'id': 5, 'key': 'estado', 'value': '08'}, {'found': True, 'id': 6, 'key': 'municipio', 'value': '019'}, {'found': True, 'id': 7, 'key': 'seccion', 'value': '0805'}, {'found': True, 'id': 8, 'key': 'localidad', 'value': '0001'}, {'found': True, 'id': 9, 'key': 'emision', 'value': '2019'}, {'found': True, 'id': 10, 'key': 'vigencia', 'value': '2029'}, {'found': True, 'id': 11, 'key': 'nacimiento', 'value': '43/09/2001'}, {'found': True, 'id': 12, 'key': 'sexo', 'value': 'H'}]}\n"
     ]
    }
   ],
   "source": [
    "# URL of the API endpoint\n",
    "url = 'http://datalegen.com/api-request'\n",
    "\n",
    "# Path to the image file you want to upload\n",
    "image_path = 'image2.jpg'\n",
    "\n",
    "# Prepare the file to be sent in the POST request\n",
    "files = {'image_file': open(image_path, 'rb')}\n",
    "\n",
    "try:\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, files=files)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Print the response JSON data\n",
    "        print('Response data:', response.json())\n",
    "    else:\n",
    "        print('Error:', response.status_code, response.json())\n",
    "except Exception as e:\n",
    "    print('An error occurred:', str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
